---
layout: page
permalink: /blogs/Sophomore Fall/8.13-8.23/index.html
title: Levi的大一上week2
---
# 8.13

今天早上首先睡到了12.00，然后下午1点开卷，点了一个苹果奶绿，感觉还是挺好喝的，然后就是听课，第一节课老师介绍了一些课程的现状，主要还是ai时代的公司特点以及deep learning 的优势，然后就是一些课程介绍。
然后的时间我首先是去搞了一些的资源，包括其余的作业，以及去把书的表填了。然后做了一点点的格式转换，然后就是听coursera的课，主要还是听课程介绍部分，包括对于NN的介绍以及对于不同算法的使用场景，然后去跑步，跑完之后摆了一会，然后写文章，复习cs229的关于unsupervised learning 的部分，然后就是继续听课，这一块应该不是讲解算法，而是主要的关于模型的选择上面，实际上非常的有用



# 8.14

:smile:今天过得非常的愉快，首先是早上8.00起床，然后8.30下床，今天是喝的luckin的绿冰沙拿铁，以及买的luchin的早点，味道还是非常不错的，然后早上首先是完成了numpy, NN的练习，然后开始听课，对于lecture2实在是不做评价

:cry:下午的时候首先是继续听lecture 3，感觉对于cs230的lecture部分做的干货比较的少，主要还是对于coursera上面的东西，我首先把神经网络的cache部分给弄清除了（主要还是通过做题熟练的），然后是学习了一些优化的方法的理论部分，以及对于regularization, optimization method(mini-batch, gradient descent)方法，最后把这门课的baseline给整理了一下下

:ship:晚上首先是去打篮球，现在已经开始完全的投三分球了，开始学习库里，但是对于长两分以及体力仍然需要练习，然后晚上随便吃了一点点，洗了个澡，然后开始卷，首先是继续做作业，做了两个programming assignment,是关于Deep Neuron Network的，然后认识了一个知乎的网友，我们相互交流，感觉非常的不错。



# 8.15

- [ ] ~~12.48-13.00休息睡觉~~
- [ ] ~~13.00-13.30完成对于regularization的部分~~
- [ ] ~~13.30-14.30完成对于下一个optimization的部分~~
- [ ] 14.30-16.30完成tensorflow部分的学习
- [ ] 16.30-17.00看Andrew Ng的Lecture 3的部分开摆

实际上这个下午直到3.30都在思考接下来的课程的事情

- [ ] [ 计算机网络PPT](https://faculty.ustc.edu.cn/bhua/zh_CN/jxzy/143921/list/index.htm)
- [ ] 赶快学习完成[离散数学](看书)的内容
- [ ] 运筹学学习[ 最优化算法]()
- [ ] 计算机系统概论阅读那本书[Introduction to computing system ]()
- [ ] 随机过程[ 看书]()
- [ ] [linux入门](https://nju-projectn.github.io/ics-pa-gitbook/ics2021/linux.html)

尤其是对于计算机系统概论而言，这一块我感觉非常的困难，而且自己完全没有了解过，然后就是对于其余的几个部分，同时还有像开学之前最好把复变函数给重新学习以下

加油



## 今日任务

- [ ] 篮球

- [ ] 学完C2

- [ ] 完成未来任务的总结

- [ ] 取快递

- [ ] 背单词

今天过得相对来说还是非常的不错的，但是晚上的时候看手机看的有一点点的多，有一部分的原因是tensorflow最一开始上手实在是有点点让人烦，晚上回去之后想要吃泡面，吃辣条，但是对于放在桂太太的快递还是没有拿。

明天早上要赶快学习随机过程了，



# 8.16

## 今日任务

- [ ] 完成随机过程前两章的学习
- [ ] 完成对于强化学习一的整理
- [ ] 背单词
- [ ] 取快递
- [ ] 打篮球
- [ ] 学完C3以及C4的全部的视频课

13.05总结

今天上午稍微的摆了一下下，睡到了9点钟，然后稍微刷了刷手机，查了查六级成绩，发现**只有567**当时的我感觉非常的不好，但是当我看到了神策也就550左右，心里平衡了一点点，然后今天上午有测量烟雾报警的人员，有修理空调外机的人员，然后就去吃饭了。



# 8.17

摆烂一天

# 8.18

对于离散数学这门课主要是若干个主题的结合，而随机过程包括了常见的平稳过程等过程，对于另外的两门专业的课程，运筹学以及计算机系统概论我是准备通过上课听课去学习了，这一年我不准备预习了，这样的话太花时间，目前主要的精力应该投入到学习cs230上。

### Afternoon

今天下午主要的时间在于学习convolutional Network的基础部分，其中包括conv layer, pad layer, poolling layer && sequaential layer,重点在于理解对于参数量（传递信息）的内容，以及对于层的设计思路，对于每一层的功能以及对于其中的**channel**的加深理解。:smile:

然后我们使用了numpy去手动实现CNN,其中debug的过程非常的艰辛，主要还是对于网络层次的更身的理解，尤其是在反向传播的时候，调参的时候，首先是对于dA_prev,dA的理解，这些东西都需要特别的注意



# 8.19

今天基本上都是摆烂，早上睡觉一觉睡到了12.00，然后刷手机到5.30，打球也优点萎靡，最后就是晚上也有点点的摆烂。明天开卷 :disappointed:

# 8.20

上午任务

- [ ] 8.20-9.00完成知乎的PS2的文章
- [ ] 9.00-9.40完成PS3文章
- [ ] 9.40-10.20完成PS4文章
- [ ] 10.20-10.30蜜雪冰城:yum:
- [ ] 10.30-12.00强化学习（一）
- [ ] 12.00-12.30吃饭:happy:
- [ ] 5.30-:basketball:

# 8.21

上午稍微摆了一点点，直接11点起床，然后回工大

下午的任务：

- [ ] 先完成对于CNN的全部内容的学习
- [ ] 完成C4W2的作业内容
- [ ] 完成对于神经网络反向传播的整理
- [ ] 完成对于强化学习第一个部分的整理
- [ ] 打篮球:basketball:
- [ ] 背单词:book:

开始完成keras_tutorial_v2a.ipynb

注意在完成keras-tutorial_v2a.ipynb之后将tensorflow，keras的版本恢复到3.0版本以及以上

```python
def model(input_shape):
    """
    input_shape: The height, width and channels as a tuple.  
        Note that this does not include the 'batch' as a dimension.
        If you have a batch like 'X_train', 
        then you can provide the input_shape using
        X_train.shape[1:]
    """
    
    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!
    X_input = Input(input_shape)

    # Zero-Padding: pads the border of X_input with zeroes
    X = ZeroPadding2D((3, 3))(X_input)

    # CONV -> BN -> RELU Block applied to X
    X = Conv2D(32, (7, 7), strides = (1, 1), name = 'conv0')(X)
    X = BatchNormalization(axis = 3, name = 'bn0')(X)
    X = Activation('relu')(X)

    # MAXPOOL
    X = MaxPooling2D((2, 2), name='max_pool')(X)

    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED
    X = Flatten()(X)
    X = Dense(1, activation='sigmoid', name='fc')(X)

    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.
    model = Model(inputs = X_input, outputs = X, name='HappyModel')
    
    return model
```



# 8.22 

Morning results:

首先完成了对于resnets的编写，然后稍微的练了一会的丹，结果发现效果不是特别的好，到了晚上我再来分析整体的原因。

然后就是学习了关于facial recognition的一半

Afternoon results:

1.学习了关于facial recognition的内容

2.学习关于picture generation的部分，但是有一点点的摆烂

2.对于clash，他是直接通过订阅国外的proxy从而得到,clash我也是不会去买的，还需要额外的购买节点，每个月大概10几rmb，不太划算



**linked in:**

wesleyfei1@163.com

password:wesley0615



**Meta.ai**

wesley0615,虽然但是这个也是需要收费的。。。

Microsoft Copilot,是与gpt一起合作的一个项目，实际上是免费的，还行。



在经过今天下午的**资料的搜寻**，我决定做这些事情

1.每天早上首先查看知乎上的浏览量，有没有新的更新文章，X上关注的博主有没有新的文章，动态以及相应的东西

2.每周至少关注一次的openai, deepmind,google ai,amazon, microsoft的动态

3.每天通过arxiv,paper with code，huggingface去看最新的论文

4.注意关注medium上的深度好文

5.注意学习知乎上相关博主的好的文章。



Evening Results:

今天晚上主要是稍微的摆烂了一会会，打球打的还可以，学习的东西只限于transfer-training 以及fine-tune

1.transfer-training

```python
preprocessed_model=tf.keras.applications.MobileNetV2(input_shape=input_shape,
                                                   include_top=False, # <== Important!!!!
                                                   weights='imagenet') # From imageNet
#这一行代码表示只保留卷积部分，不保留全连接层
#使用MobileNetV2在imagenet上面的训练出来的数据结果

# pay attention to include_top=False

def model()：
	x=preprocessed_model(input)
    X=...
    X=...
    return X

```

2.微调模型（fine-tune)

```python
# 我们想要从某一层开始调整
preprocessed_model.trainable=True# 先调整为全部可以训练的
fine_tune_layers=len(preprocessed_model.layers)-25# 有25层可以训练
for layer in preprocessed_moedl.layers[:fine_tune_layers]:
    layer.trainable=False
```

通过以上的操作就可以对于已经给定的模型进行微调，并对于最后的几个层进行调整

而如果我们希望从倒数的某一层开始输出

```python
second_output=preprocessed_model.output[:-2]
X=Conv2D(.....)(second_output)
```



下班下班！！！:happy::happy::happy:

今天总结了我需要做什么，听完了C4W3，W4的课程，以及完成了C4W2的三份作业，包括keras的使用教程，对于resnets的实现细节以及fine tune, transfer-training的知识点，但是同时还是有一点点的摆烂的，之后不可以这样的。

**之后在图书馆的时候手机不能放在桌面上，如果有任何急切需要做的事情，先写在markdown上面。**

突然发现自己的论文堆里面还存了一堆又一堆的论文，而且自己对于这些知识点的记录简直是一坨，还是需要努力

# 8.23

```python
# 对于neural style transfer 的一些总结
# 模型加载
vgg = VGG19(include_top=False, weights='imagenet', input_shape=(IMAGE_H, IMAGE_W, 3))
vgg.trainable = False

model = Model(inputs=vgg.input, outputs=vgg.output)
# 定义输出
def total_costs()
...
def compute_content_cost()
...
def compute_style_cost()
...
def get_layer(model,image):
    # 如果我们想要提取特定某一层的输出，那么使用
    # name_layer_output=model.get_layer('block5_conv2').output
    output_layer=[model.get_layer(layer).output for layer in model.layers]
    return output_layer
# 实际上就是对于keras需要一层层的获取其输出
# 训练步骤
def train_step(model,content_picture,style_picture,)
	with tf.GradientTape() as tape:
        features = model(generated_image)
        feature_layer=get_layer(generated_image)
        style_layer=get_layer(generated_image)
        J_content=compute_content_cost(features,model(content_picture))
        J_style=compute_style_cost(,model_structure)
        loss=total_costs(J_content,J_style,alpha,beta)
    
	grads=tape.gradient(loss,picture)
	optimizer.apply_gradients(zip(grads,picture))
	return loss

for step in range(EPOCHS):
    loss=train_step(....)
    # print the results
    
```

总结下来，这一块实际上就是对于keras以及自己训练模型的一个总结。

对于keras可以规定一个模型，model=(input=...,output=...),同时如果对于其内部有一些东西可以进行微调，可以使用trainable进行调整

而如果我们想要在前方或者是最后面加上若干层，那么就可以规定一个自己的model

然后规定optimizer的类型，规定loss,如果对于train-step中有已经有的东西，就直接使用

```python
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
```

否则的话就使用tensorflow本身的东西

```python
with tf.GradientTape() as tape:
    loss=()
grads=tape.gradient(loss, the causes)
optimizer.apply_gradients(zip(grads,picture))
for step in range(EPOCHS):
    ....
```

感觉之后这一段的东西可以写成一篇文章：keras&以及tensorflow训练总结以及实际演练了。



---

而对于neural style transfer的内部的结构（已知的网络，对于输入本身做梯度下降，对于损失函数的定义）这些都属于内部的一些小小的细节了。

![image-20250823164907265](D:\WesleyFei\wesleyfei1.github.io\wesleyfei1.github.io\blogs\image-20250823164907265.png)

刚刚做了一个cpti的测试，感觉非常的有趣[CPTI测试入口](https://cpti.browserfly.app/zh/)

## 知乎体验

对于以后写文章的时候，我发现，直接把typora中间的所有的东西给弄出来，然后对于图片以及数学公式的部分单独去显示

## Evening 

对于 **Face_Recognition_v3a**的学习记录表现

首先是在debug的时候

1.对于NCHW的形式的话是只有GPU下的tensorflow才可以使用，对于其使用方式为

```python
from tensorflow.keras import backend as K
K.set_image_data_format('channels_first')
```

然后对于数据的输入为

```python
img = tf.keras.preprocessing.image.load_img(image_path, target_size=(96, 96))
img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)
```

对于模型而言，对于keras框架下面的每一个层的定义，都需要

```python
X_1x1 = Conv2D(64, (1, 1), data_format='channels_first',name='inception_3b_1x1_conv')(X)
X_1x1 = BatchNormalization(axis=1, epsilon=0.00001, name='inception_3b_1x1_bn')(X_1x1)#batch normalization wants to depressed the stuff on the channels
inception = concatenate([X_3x3, X_5x5, X_pool, X_1x1], axis=-1)#when pack various stuff, we need to pay attention to the channels
```

就debug，包括对于data的形式的转变，对于模型的转换，我在这个仿麦呢就画了不知道多少时间。

2.对于这个题目本身，主要是对于triplet_loss这个东西

```python
def triplet_loss(y_true, y_pred, alpha = 0.2):
    
    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]
    
    distance_ap=tf.reduce_sum(tf.square((anchor-positive)),axis=-1)
    distance_an=tf.reduce_sum(tf.square((anchor-negative)),axis=-1)
    distance=tf.maximum(distance_ap-distance_an+alpha,0)
    loss=tf.reduce_sum(distance)
    
    return loss
```

数学的表示就是

如果是facial_clarrification，那么就比较

```python
model(image),database[name]
```

否则的话，选择distance最小的一个然后进行比较

$$\mathcal{J} = \sum^{m}_{i=1} \large[ \small \mid \mid f(A^{(i)}) - f(P^{(i)}) \mid \mid_2^2 - \mid \mid f(A^{(i)}) - f(N^{(i)}) \mid \mid_2^2+ \alpha \large ] \small_+ \tag{3}$$为我们的比较函数



以上就是今天晚上我们做的事情，今天打篮球打的也还可以，但是感觉左侧大腿有一点点的**拉伤**，但是今天做了一件比较不错的事情，那就是成功的把三级斗兽场给打过了，而且我们发现**丝之歌**终于更新了，真的是超级激动狂喜。





突然发现有任何的东西记录在这个typora上面是一个非常好的需要保持的习惯。

今天发现了一个印度理工的小伙子，非常的卷

[nishchal kumar](https://nishchal-29.github.io/Nishchal-29.gitgub.io/)
