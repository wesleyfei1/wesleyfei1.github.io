# 9.14

由于大模型的发展，我们不需要完全重新的训练，而是使用**大模型的pretrain**应用到具身智能中。

而训练的时候的主要的途径为RL&世界模型

目前的大模型的问题是当我们同时输入图片以及指令的时候，要么只考虑图片中的信息，要么只考虑指令的信息，同时模型会put too much emphasis on 最后的信息。这些都是有趣的问题





对于一位学长的方向：泛化数据

泛化数据而言：硬件上的限制，数据处理效率低下，然后我们需要使用一些有趣的手段去进行数据的处理

Peter:AGI 

BaseModel不够强，人与机器训练

视觉模型



具身智能的未来架构：

VLA,VLM,分层架构

 [具身智能高新9.14笔记.pdf](具身智能高新9.14笔记.pdf) 

文本数据以及图片(视觉)的数据最后会得到相同的结果



- [ ] VLA
- [ ] VLM
- [ ] LLA这些比较常见的概念
- [ ] 退火

这些是一些需要掌握的概念之后去进行学习





