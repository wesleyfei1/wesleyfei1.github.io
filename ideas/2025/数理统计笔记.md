---
layout: page
permalink: /ideas/2025/数理统计笔记/index.html
title: 数理统计笔记
---
# 数理统计
关于数理统计这一块，我们在对于一串的数据进行处理的时候，首先是估计，对于一些想要了解的量的估计，以及在那些区间段，可以有多少的程度的估计，这些是常见的问题，而如果我们有了一个小小的假设，我们要用这一串的数据去进行验证以及对于未来的预测，从而我们需要进行假设检验以及回归分析
## Chap 5 统计学基本概念
1.总体：研究对象的某个指标的全体以及这些值的概率分布->总体
  样本：从总体中按照一定的方式抽取n个个体X=(X1,X2...Xn),成为是样本量为n的一个样本。
注：如果是简单随机抽样(独立性，同样分布)那么有$\Pi f(x_i)=f(x_1)f(x_2)...f(x_n)$,而对于样本可以视为是随机变量，也会有一定的概率分布，称之为是样本分布
  统计量：完全由样本X=(X1,X2,...Xn)决定的量称为是统计量，而其中的完全就是说统计量中不可以由其余的未知的参数
常见的统计量包括$\bar{X}=\frac{1}{n}\Sigma X_i$样本方差$S^2=\frac{1}{n-1}\Sigma(X_i-\bar{X})^2$,样本矩$a_k=\frac{1}{n}\Sigma X_i^k$,而当样本是简单随机样本时，$\bar{X}->\mu,m_2->\sigma^2$
2.抽样分布：设(X1,X2,...Xn)为一个样本，统计量T=T(X1,X2...Xn)的分布称为时抽样分布(可以类比是抽取了n个变量，构成的一个新的统计量的分布情况)(对于以下的常见的分布情况，重要的是其意义以及概念)
- $\chi^2$分布
  1.定义：设样本(X1,X2,...Xn)为来自于Xi~N(0,1)的一个简单随机样本，称$X=X_1^2+X_2^2+...+X_n^2$,为服从自由度为n的$\chi^2分布，记为X-\chi^2_n$
  2.性质：(1)E(X)=n,Var(X)=2n; (2)$X-\chi^2_m,Y-\chi^2_n,X+Y-\chi^2_{m+n}$
  3.对于$P(X>c)=\alpha,c$称为是自由度为n的卡方分布的上$\alpha$位数
- t分布
  1.定义：设$X\sim N(0,1),Y\sim\chi^2_n,且X,Y互相独立，称T=\frac{X}{\sqrt{Y/n}}为服从自由度为n的t分布，记为T\sim t_n$
  2.性质：对于n趋近于正无穷，tn的分布的概率密度函数趋于标准正态分布函数，同样的，对于$P(T>c)=\alpha, c=t_n(\alpha)称为是自由度为n的t分布的上\alpha分位数$
- F分布
  1.定义：$设X\sim\chi^2_m,Y\sim\chi^2_n,XY相互独立，称F=\frac{X/m}{Y/n}为服从自由度为m,n的F分布，记为F\sim F_{m,n}$
  2.性质：$F_{m,n}(1-\alpha)=1/F_{n,m}(\alpha)$
- 相关重要的性质
  设$X_i i.i.d.\sim N(\mu,\sigma^2),c_i为不全为0的常数，则有$
  (1)$T=\Sigma c_kX_k \sim N(\mu \Sigma c_k,\sigma^2\Sigma c_k^2),特别的，对于ci全部相等时，有\bar{X}\sim N(\mu,\frac{\sigma^2}{n})$
  (2)$S^2=\frac{1}{n-1}\Sigma(X_i-\bar{X})^2为样本方差，则有\frac{(n-1)S^2}{\sigma^2}\sim \chi^2_{n-1}$(证明就是对于S^2可以对应到一个自由度为n-1的Yi的分布上面。而这个可以由施密特正交化保证)
  (3)从而有$\frac{\sqrt{n}(\bar{X}-\mu)}{S}\sim t_{n-1}$
->于是可以有几个小小的推论
(1)若$X_i\sim N(\mu_1,\sigma^2_1),Y_i\sim N(\mu_2,\sigma_2^2)而且两者的方差一样，则有T=\frac{\bar{X}-\bar{Y}-(\mu_1-\mu_2)}{S_T}\sqrt{\frac{mn}{m+n}}\sim t_{m+n-2},(n+m-2)S_T^2=(m-1)S_X^2+(n-1)S_Y^2$
## Chap6 参数点估计 && Chap 7 区间估计
以下的这两个东西是对于给定了一组的数据，希望对于其中的某一个统计量的大小或者其区间进行一些估计
1.参数点估计：对于已经有了从总体中抽取的样本X=(X1,X2..Xn),用样本对于参数$\theta_1,\theta_2...\theta_k$进行估计，为了估计$\theta_1,需要构造相应的统计量\hat{\theta_1}(X)$,并称之为、theta_1的估计量，以及相应的估计值而使用theta的统计量去估计另外的一个点，称之为是点估计
2.矩估计法：
方法：将样本矩来近似总体矩：$\mu\approx\frac{1}{n}\Sigma X_i,\sigma^2=\frac{1}{n}\Sigma(X_i-\bar{X})^2$之类的东西
3.最大似然估计：
思想：对于统计N的大小的时候，考虑在当满足要求的情况下的f(n),取n最大的时候的n即为最大似然估计
(1)定义：似然函数,设样本X=(X1,X2...Xn)有概率密度函数，则有$f(\mathbf{x};\theta)=f(\mathbf{x};\theta_1,\theta_2,...\theta_k)$,x称为是X的一个样本值，在固定x的时候将f看成是\theta的函数，称为是似然函数$L(\theta)$
(2)统计方法：$L(\theta^*_1,\theta^*_2,...\theta^*_k;x_1,x_2...x_k)=max_{\mathbf{\theta}}L(\theta_1,\theta_2...\theta_k;x_1,x_2...x_n),可以通过求驻点\frac{\partial l}{\partial \theta_i}=0$
一般而言，对于L都是将所有的f都乘起来(相互独立)
4.优良性准则:对于以上的矩估计以及最大似然估计都是比较好的方法，但有的时候又如何评价这些东西嫩，从而我们应该从整体性能上面比较
- 点估计的无偏性(减少系统误差)
  (1)定义：偏差与无偏性$设\hat{g}(X_1,x_2,...X_n)为g(\theta_1,\theta_2...\theta_k)的一个估计量，称E_\theta(\hat{g}(X_1,x_2,...X_n))-g(\theta_1,\theta_2...\theta_k)为估计量\hat{g}的偏差，若这个偏差为0那么就称\hat{g}为g的一个无偏估计量$
  注：1.独立重复进行N次观测，则又均值由大数定律收敛，从而当N充分大的时候，估计的均值收敛于g
    2.我们常常只会对于一个变量进行这样的估计，因此常用的是设总体分布的一个统计量是A,由关于样本的估计量$\hat{\theta_1}$,求是否是无偏估计
    - 方法就是$E(\hat{\theta_1})?=A$如果成立，就是无偏估计，反之则不然**比如对于样本方差前面的系数是为了保证是无偏估计**
- 最小方差无偏估计
  (1)定义：$\hat{\theta_1},\hat{\theta_2}都是总体参数\theta的无偏估计，方差存在，且Var_\theta(\hat{\theta_1})\leq Var_\theta(\hat{\theta_2})且等号不恨成立，则\theta_1更好，相应的最下的\hat{\theta_0}称为是g(\theta)的一个最小方差无偏估计$
  (2)Kram-lao方差下限
  以及在大样本的时候会由$\hat{\theta}-\theta/(\sigma(\theta))为一个正太分布$
---
区间估计：在这个区间段内有多少百分比的概率是可以相信的
4.置信区间和置信系数：设(X1,X2...Xn)是从总体中抽取的一个简单随机样本，$\theta是一个未知的参数，\hat{\theta_1}(X_1,X_2..X_n)<\hat{\theta_2(X_1,X_2..X_n)},若P_\theta(\theta_1\geq \theta \leq \theta_2)=1-\alpha,称[\theta_1,\theta_2]为\theta的置信区间，置信系数为1-\alpha$
注：对于置信区间是建立在点估计的基础上面的，即为对于在$\hat{\theta}$的左右两侧的一定的区域内部会有多少的置信系数
5.枢轴变量法：
方法：(1)找到一个$\theta$的良好点估计T(X),一般为最大似然估计
(2)构造一个函数，S(T,U,theta)其中U为统计量，分布已知，
(3)将$a\leq S(T,U,\theta)\leq b$改写称A<=theta<=B,而对于给定了置信区间的时候就$a,b为F的上\alpha/2，1-\alpha/2则有P(a\leq S \leq b)=1-\alpha$既有[A,B]为theta的置信系数为1-alpha的置信区间
常用结论：对于正态分布总体均值X的置信区间为$\hat{x}\pm d，当\sigma^2已知或者当n非常大，可以认为满足大数定律的时候，为\frac{\hat{\sigma}}{\sqrt{n}}u_{\alpha/2}$,$其余情况下面，则为\frac{s}{\sqrt{n}}t_{n-1}(\alpha/2)$,而我们在使用以上的这些东西的时候常常会使用到之前的分布中的常见的公式以及一些其几何意义，特别是关于t分布以及卡方分布
6.大样本方法：对于以上的数轴分布的难点就是$S(T,U,\theta)于\theta$要是没有关系的，这个东西有一定的难度，英雌我们来讨论关于构造比例p的置信区间，而这一个步骤可以使用总体均值的优良点估计去完成
(1)由于当n充分大的时候，$\frac{Y_n-np}{\sqrt{np(1-p)}}\sim N(0,1)$,从而有$-u_{\alpha/2}\leq \frac{y_n-np}{\sqrt{np(1-p)}}\leq u_{\alpha/2}$,从而可以解出来p的范围p表示的是时间A在每一次实验中发生的概率，Yn为A发生的次数
7.自助法置信区间：
对于给定了样本量为n的样本下，由于n比较少，无法的到相应的连续的区间来判断其百分位数，于是使用
方法：
(1)从x1,x2...xn中又放回的取出来样本量为n的样本，称为是一个自主样本(2)基于该样本计算统计量的值并重复以上步骤多次，近似为\theta的自助分布
## Chap 8 假设检验
假设检验即为对于统计总体的性质做出的假设并利用样本对于假设进行检查的方法，如果对于总体分布的类型是已知的，那么就是参数假设检验，若是其余的类型，那么就是非参数检验 
1.一些的名词：H0原假设，H1备择假设，两点假设，双侧假设，单侧假设
检验统计量(验证一个假设时所用到的统计量)，接受域(使原假设得到接受的样本所在的区域A),临界值(C1<X<C2此时C1C2都是临界量)
(1)功效函数：$\beta_\Psi(\theta)=P_{\theta}(在(X1,X2,....Xn)给定下H_0被否定)->\Psi的功效函数$,若有X是备择假设，希望beta更大，反之希望更小
(2)检验水平：$\beta_{\Psi}(\theta)\leq \alpha, \forall \theta \in H_0，so \Psi为H_0的一个水平\alpha的检验$
(3)两类错误：$当X\in H_0时，拒绝H_0->第一类错误，当X\in H_1,不拒绝H_0第二类错误，当\theta\in H_0，一类错误概率\beta_\Psi (\theta),当\theta \in H_1, 二类错误为1-\beta_\Psi (\theta)$，对于优先控制第一类错误->显著性检验(更加拒绝H0)
方法：(1)提出假设(2)使用标准化后的检验统计量(3)拒绝域为T<A的形势，从而(4)在H0的条件下满足T<A的式子，取A为、alpha的上\alpha分位数，而对于H0,如果不符合H0,就可以认为式H1,没有别的情况
2.正态总体参数检验
(1)单个正态总体均值检验：常见假设类型:a.H0 x>x0 b.x<x0 c.x=x0相应的拒绝域形式为相应的单侧区间，双侧区间
- $\sigma^2$已知的情况
  由于对于X和均值的差距不大，英雌若备择假设成立，x应该比μ0小，从而可以有
  (1)$\Psi:当Z=\frac{\sqrt{n}(\bar{X}-\mu_0)}{\sigma}<C时拒绝原假设H_0,否则不可以拒绝$
  (2)为了让检验有给定的水平\alpha,有$\beta_\Psi(\mu)=P_\mu(Z<C)在所有的\mu\geq\mu_0时有\beta\leq\alpha,soC=-u_\alpha$(alpha越大，则u越小，那么容许第一类错误的概率越大)
  (3)从而对于要求第一类为α，第二类为beta的时候由于$\beta_\Psi(\mu)=P_\mu(C2<Z<C1)而对于N(Z<C)即为\Phi(C)形式的正态分布的分布函数$
  对于检验问题2，同理，而对于问题3，有1-α=P(|Z|<C)从而对于其中的C即可，而在使用的时候**计算索要检验的东西的检验统计量T，计算T和显著性水平下的灵界两下是否在拒绝域里面**
  >注：对于没有给定方差的时候，使用t(n-1)分布即可

(2)对于多个正态总体均值的检验：即为考虑X-Y这个统计量的均值，方差
$\sigma'=\sigma\sqrt{\frac{1}{m}+\frac{1}{n}},S'=\frac{(m-1)S_1^2+(n-1)S_2^2}{m+n-2}$即可
(3)对于正太总体方差的检验
以$H_0:\sigma^2\geq\sigma_0^2<->\sigma^2<\sigma_0^2$为例
$S^2=\frac{1}{n-1}\Sigma(X_i-\bar{X})^2,而统计量为\frac{(n-1)S^2}{\sigma^2}\sim \chi^2_{n-1}$于是只要设置相应的C以及置信系数即可
3.比例p的检验:对于Xi~B(1,p),以假设H0:p<p0为例
$\psi:当\bar{X}>C的时候拒绝H_0,so\beta_\psi(p)=P(S>C)=1-\Sigma(_i^n)p^i(1-p)^{n-i}=\alpha即可$
4.似然比检验：
对于$H_0:\theta \in \Theta_0andH_1: \theta\in \Theta\Theta_0$,而解释的时候L1(x)/L0(x)若比值比较大，那么使用H1解释，否则使用H0解释
(1)似然比检验：$LR(x)=sup_{\theta\in\Theta}f(x;\theta)/sup_{\theta\in\Theta_0}f(x;\theta)$当LR(x)>c的时候拒绝原假设，否则不可以

5.p值：p=P(得到和当前样本下检验统计量之值一样或更加极端|原假设下)，而p<α拒绝H0,常使用自助法来得到p值

## Chap 9 非参数假设检验
1.拟合优度检验：
(1)理论分布完全已知且只有有限个值
$假设已经有一组的样本(x1,x2,...xn),我们假设满足P(X=ai)=pi,则Z=\Sigma\frac{n_i^2}{np_i}-n，由已知定理，Z\sim \chi_{k-1}^2$
$因此，Z>\chi_{k-1}^2(\alpha)时拒绝H_0$
(2)理论分布类型已知含有有限个未知数
对于$P(X=a_i)=p_i(\theta_1,\theta_2,......\theta_r)，对于每一个\theta_i考虑用其最大似然估计/矩估计\hat{\theta_i}代替，Z=\Sigma\frac{n_i^2}{n\hat{[p_i]}}-n满足Z\sim\chi_{k-r-1}^2$
(3)对于X为无穷个值或者时连续型的变量，考虑讲整个区间段分割称多个小区间，从而定义$Y=a_i,x_{i-1}<X\leq x_i$
2.列联表检验$p_{ij}=p_ip_j,从而由相应的统计量以及分布$
3.Wilson值和检验同样的道理，其余的东西就略了
## Chap 10 相关分析与回归分析
以下我们只讨论关于一位的变量之间的回归分析，对于多维的情况下面使用矩阵的知识点，之后满满学
1.相关分析：
比例数据：$r_p=\frac{S_{xy}}{\sqrt{S_{xx}S_{yy}}}=\frac{Cov(X,Y)}{Var(X)Var(Y)}$,临界点0.3，0.5，0.8
有序数据：$r(X,Y)=\Sigma_{i<j}sgn((X_i-X_j)(Y_i-Y_j))/(0.5n(n-1))$为肯德尔相关系数，表示对于秩的估计
2.回归分析
对于Y=f(x1,x2...xp)+e//e为随机误差
线性回归$y_i=a+\beta_1x_i+e_i,\hat{\beta_1}=\frac{S_{xy}}{S_{xx}},\hat{a}=\bar{y}-\hat{\beta_1}\bar{x}$
以上时大概的一个思路，实际上就是对于一堆的数据分析，参数的估计，在那些的区间上可以象形，对于某一个假设的验证，包括是某个参数，以及对于一个分布的验证，同时对于给定的一堆的数据的拟合情况，以上就是对于数理统计的一个大致的整理
